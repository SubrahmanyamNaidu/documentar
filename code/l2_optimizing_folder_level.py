import os
import json
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
load_dotenv()

def get_repo_structure(repo_path, exclude_dirs={".git", ".github", "node_modules"}, exclude_files={".gitignore",".gif",".png",".jpg",".jpeg"}):
    repo_dict = {}

    for root, dirs, files in os.walk(repo_path, topdown=False):  # Bottom-Up Traversal
        relative_path = os.path.relpath(root, repo_path)

        # Skip paths containing .git or other excluded directories
        if any(excluded in root.split(os.sep) for excluded in exclude_dirs):
            continue

        # Remove excluded directories from traversal
        dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.startswith(".")]

        repo_dict[relative_path] = {
            "path": root,
            "sub-folders": {d: {"path": os.path.join(root, d)} for d in dirs},
            "files": [
                {"filename": f, "path": os.path.join(root, f)}
                for f in files if f not in exclude_files and not f.startswith(".")
            ]
        }

    return repo_dict





def generate_description(file_path, content=None):
    prompt = f"Describe the purpose of this file in a software project:\nFile: {file_path}\n"
    
    if content:
        prompt += f"Content: ```{content[:500]}```\n"  # Only first 500 chars to avoid cost

    chat = ChatOpenAI(model="gpt-4o-mini")
    response=chat.invoke(("user", prompt))
    print(response.content)
    return response.content


def build_json_with_descriptions(repo_dict):
    for key, value in repo_dict.items():
        file_descriptions = []  # List to collect file descriptions for the folder
        subfolder_descriptions = []  # List to collect subfolder descriptions
        folder_name = key  # Use the folder name as part of the prompt

        # Process files in the current folder
        for file in value.get("files", []):
            # Read file content and generate description using LangChain GPT-4
            with open(file["path"], "r", encoding="utf-8", errors="ignore") as f:
                file_content = f.read()
                file["description"] = generate_description(file["filename"], file_content)
            
            # Collect file descriptions along with their names for the prompt
            file_descriptions.append(f"File: {file['filename']}\nDescription: {file['description']}")

        # Process subfolders in the current folder
        for subfolder, subfolder_data in value.get("sub-folders", {}).items():
            subfolder_name = subfolder
            # Generate a description for the subfolder using its file contents
            subfolder_files = subfolder_data.get("files", [])
            subfolder_description = []  # Collect descriptions of files in the subfolder
            
            for subfile in subfolder_files:
                with open(subfile["path"], "r", encoding="utf-8", errors="ignore") as f:
                    subfile_content = f.read()
                    subfile["description"] = generate_description(subfile["filename"], subfile_content)
                
                subfolder_description.append(f"File: {subfile['filename']}\nDescription: {subfile['description']}")

            # If there are descriptions for this subfolder, add to the subfolder list
            if subfolder_description:
                subfolder_descriptions.append(f"Subfolder: {subfolder_name}\n" + "\n".join(subfolder_description))

        # Combine file and subfolder descriptions into a single prompt for overall folder description
        folder_description_prompt = f"Given the following descriptions of files and subfolders in the folder '{folder_name}', summarize the overall purpose of the folder:\n"
        folder_description_prompt += "\n".join(file_descriptions + subfolder_descriptions)
        
        # Get the folder-level description from OpenAI
        folder_description = generate_description("Folder", folder_description_prompt)

        # Store the folder's overall description generated by OpenAI
        value["description"] = folder_description

    return repo_dict



def json_to_markdown(repo_dict):
    md = "# Repository Documentation\n\n"

    for folder, data in repo_dict.items():
        md += f"## üìÅ {folder}\n"
        md += f"- **Path:** `{data['path']}`\n"
        md += f"- **Description:** {data['description']}\n\n"

        for file in data.get("files", []):
            md += f"### üìÑ {file['filename']}\n"
            md += f"- **Path:** `{file['path']}`\n"
            md += f"- **Description:** {file.get('description', 'No description available.')}\n\n"

    return md

if __name__=="__main__":
    repo_path = "./lawndepot-api"
    repo_structure = get_repo_structure(repo_path)
    repo_with_descriptions = build_json_with_descriptions(repo_structure)

    # Save as JSON
    with open("l2_opt_lawn_repo_documentation.json", "w",encoding="utf-8") as f:
        json.dump(repo_with_descriptions, f,ensure_ascii=False, indent=4)

    # Save as Markdown
    md_content = json_to_markdown(repo_with_descriptions)
    with open("l2_opt_lawn_repo_documentation.md", "w",encoding="utf-8") as f:
        f.write(md_content)

    print("üìÑ Documentation Generated Successfully!")
